import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from xgboost import XGBClassifier
from sklearn.cluster import KMeans, AgglomerativeClustering
from sklearn.metrics import (accuracy_score, precision_score, recall_score,
                             f1_score, roc_auc_score, confusion_matrix,
                             classification_report, roc_curve, silhouette_score)
from imblearn.over_sampling import SMOTE
import warnings

warnings.filterwarnings('ignore')

# Set style
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (12, 6)

print("=" * 80)
print("PART B: DATA MODELLING AND EVALUATION")
print("Stroke Prediction Using Machine Learning")
print("=" * 80)



print("\n" + "=" * 80)
print("SECTION 1: DATA PREPARATION")
print("=" * 80)

# Load cleaned data
df = pd.read_csv('stroke_data_cleaned.csv')
print(f"\nLoaded cleaned dataset: {df.shape[0]} rows √ó {df.shape[1]} columns")

# Check class distribution
print("\nTarget variable distribution:")
print(df['stroke'].value_counts())
print(f"Class imbalance ratio: {(df['stroke'] == 0).sum() / (df['stroke'] == 1).sum():.2f}:1")


print("\n" + "=" * 80)
print("SECTION 2: FEATURE ENGINEERING (ENHANCED)")
print("=" * 80)

df_model = df.copy()

# Drop ID column
if 'id' in df_model.columns:
    df_model = df_model.drop('id', axis=1)

# --- STANDARD FEATURES (You already had these) ---

# Categorical Bins
df_model['age_group'] = pd.cut(df_model['age'],
                               bins=[0, 40, 50, 60, 70, 100],
                               labels=['<40', '40-49', '50-59', '60-69', '70+'])

def categorize_bmi(bmi):
    if bmi < 18.5: return 'Underweight'
    elif bmi < 25: return 'Normal'
    elif bmi < 30: return 'Overweight'
    else: return 'Obese'
df_model['bmi_category'] = df_model['bmi'].apply(categorize_bmi)

def categorize_glucose(glucose):
    if glucose < 100: return 'Normal'
    elif glucose < 126: return 'Pre-diabetic'
    else: return 'Diabetic'
df_model['glucose_category'] = df_model['avg_glucose_level'].apply(categorize_glucose)

# Binary Indicators
df_model['is_elderly'] = (df_model['age'] >= 65).astype(int)
df_model['is_obese'] = (df_model['bmi_category'] == 'Obese').astype(int)
df_model['has_comorbidity'] = ((df_model['hypertension'] == 1) | (df_model['heart_disease'] == 1)).astype(int)



# 1. Non-Linear Age (Captures exponential risk increase)
df_model['age_squared'] = df_model['age'] ** 2

# 2. Vascular Danger Synergy (Hypertension + Heart Disease)
df_model['hyper_heart_interaction'] = df_model['hypertension'] * df_model['heart_disease']

# 3. Log-Transformed Glucose (Normalizes skewed distribution)
df_model['log_glucose'] = np.log1p(df_model['avg_glucose_level'])

# 4. Total Risk Score (Enhanced)
df_model['risk_score_total'] = (
    df_model['hypertension'] +
    df_model['heart_disease'] +
    df_model['is_elderly'] +
    df_model['is_obese'] +
    (df_model['glucose_category'] == 'Diabetic').astype(int)
)

print("\n‚úì Added Advanced Features:")
print("  - age_squared (Non-linear risk)")
print("  - hyper_heart_interaction (Synergy)")
print("  - log_glucose (Distribution smoothing)")
print("  - risk_score_total (Summary metric)")



print("\n" + "-" * 80)
print("2.5 Correlation Analysis")
print("-" * 80)

# For correlation, we need numeric representation of categorical variables
# Create a temporary dataframe with numeric encoding
df_corr = df_model.copy()

# Encode categorical variables as numeric for correlation
categorical_to_encode = ['gender', 'ever_married', 'work_type', 'Residence_type',
                         'smoking_status', 'bmi_category', 'glucose_category', 'age_group']

for col in categorical_to_encode:
    if col in df_corr.columns:
        df_corr[col] = pd.Categorical(df_corr[col]).codes

# Select relevant features for correlation
features_for_corr = ['age', 'gender', 'hypertension', 'heart_disease',
                     'ever_married', 'avg_glucose_level', 'bmi',
                     'is_elderly', 'has_comorbidity', 'age_squared',
                     'hyper_heart_interaction', 'log_glucose', 'risk_score_total', 'stroke']

# Calculate correlation matrix
correlation_matrix = df_corr[features_for_corr].corr()

# Display top correlations with stroke
stroke_correlations = correlation_matrix['stroke'].sort_values(ascending=False)
print("\nTop Correlations with Stroke Outcome:")
print(stroke_correlations.head(10))

# Create correlation heatmap
plt.figure(figsize=(14, 12))
sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm',
            center=0, square=True, linewidths=1, cbar_kws={"shrink": 0.8},
            vmin=-1, vmax=1)
plt.title('Correlation Matrix: Features vs Stroke Outcome',
          fontweight='bold', fontsize=14)
plt.tight_layout()
plt.savefig('correlation_heatmap.png', dpi=300, bbox_inches='tight')
plt.show()

print("\n‚úì Saved: correlation_heatmap.png")



# Update Selected Features List
selected_features = [
    # Original Numeric
    'age', 'avg_glucose_level', 'bmi',
    # Original Categorical
    'gender', 'hypertension', 'heart_disease', 'ever_married',
    'work_type', 'Residence_type', 'smoking_status',
    # Engineered
    'is_elderly', 'is_obese', 'has_comorbidity',
    'bmi_category', 'glucose_category',
    # NEW Advanced
    'age_squared', 'hyper_heart_interaction', 'log_glucose', 'risk_score_total'
]

X = df_model[selected_features].copy()
y = df_model['stroke'].copy()

# Encoding
categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()
X_encoded = pd.get_dummies(X, columns=categorical_cols, drop_first=True)

print(f"\n‚úì Final Feature Count: {X_encoded.shape[1]}")



print("\n" + "=" * 80)
print("SECTION 3: TRAIN-TEST SPLIT (80/20 STRATIFIED)")
print("=" * 80)

X_train, X_test, y_train, y_test = train_test_split(
    X_encoded, y, test_size=0.2, random_state=42, stratify=y
)

print(f"\nTraining set: {X_train.shape[0]} samples")
print(f"  No Stroke: {(y_train == 0).sum()} ({(y_train == 0).sum() / len(y_train) * 100:.1f}%)")
print(f"  Stroke: {(y_train == 1).sum()} ({(y_train == 1).sum() / len(y_train) * 100:.1f}%)")

print(f"\nTest set: {X_test.shape[0]} samples")
print(f"  No Stroke: {(y_test == 0).sum()} ({(y_test == 0).sum() / len(y_test) * 100:.1f}%)")
print(f"  Stroke: {(y_test == 1).sum()} ({(y_test == 1).sum() / len(y_test) * 100:.1f}%)")



print("\n" + "=" * 80)
print("SECTION 4: FEATURE SCALING")
print("=" * 80)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)
X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)

print("‚úì Features scaled using StandardScaler (mean=0, std=1)")



print("\n" + "=" * 80)
print("SECTION 5: HANDLING CLASS IMBALANCE WITH SMOTE")
print("=" * 80)

print("\nOriginal training class distribution:")
print(f"  No Stroke: {(y_train == 0).sum()}")
print(f"  Stroke: {(y_train == 1).sum()}")
print(f"  Ratio: {(y_train == 0).sum() / (y_train == 1).sum():.2f}:1")

smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)

print("\nAfter SMOTE:")
print(f"  No Stroke: {(y_train_smote == 0).sum()}")
print(f"  Stroke: {(y_train_smote == 1).sum()}")
print(f"  Ratio: 1:1 (Balanced)")

print(f"\n‚úì Training set size: {len(y_train)} ‚Üí {len(y_train_smote)} samples")



print("\n" + "=" * 80)
print("SECTION 6: BASELINE MODELS (DEFAULT PARAMETERS)")
print("=" * 80)

baseline_models = {
    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),
    'Naive Bayes': GaussianNB(),
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
    'SVM': SVC(probability=True, random_state=42)
}

baseline_results = []

for name, model in baseline_models.items():
    print(f"\nTraining {name}...")
    model.fit(X_train_smote, y_train_smote)

    y_pred = model.predict(X_test_scaled)
    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]

    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred, zero_division=0)
    rec = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    auc = roc_auc_score(y_test, y_pred_proba)

    print(f"  Accuracy:  {acc:.4f}")
    print(f"  Precision: {prec:.4f}")
    print(f"  Recall:    {rec:.4f}")
    print(f"  F1-Score:  {f1:.4f}")
    print(f"  AUC-ROC:   {auc:.4f}")

    baseline_results.append({
        'Model': name,
        'Type': 'Baseline',
        'Accuracy': acc,
        'Precision': prec,
        'Recall': rec,
        'F1-Score': f1,
        'AUC-ROC': auc
    })


# Calculate the scale factor for XGBoost
# ratio = negative_count / positive_count
ratio = (y_train == 0).sum() / (y_train == 1).sum()

print("\n" + "=" * 80)
print("SECTION 7 (IMPROVED): COST-SENSITIVE OPTIMIZATION")
print("=" * 80)

# 1. Logistic Regression with Balanced Weights
lr_param_grid = {
    'C': [0.01, 0.1, 1, 10],
    'penalty': ['l2'],
    'solver': ['lbfgs'],
    'class_weight': ['balanced'] # Automatically adjusts weights
}

print("Optimizing Weighted Logistic Regression...")
lr_grid = GridSearchCV(LogisticRegression(max_iter=1000), lr_param_grid,
                       cv=5, scoring='recall', n_jobs=-1)
lr_grid.fit(X_train_scaled, y_train)

# 2. Random Forest with Balanced Subsample
rf_param_grid = {
    'n_estimators': [200, 500],
    'max_depth': [5, 10, None],
    'class_weight': ['balanced_subsample'], # Adjusts weights per tree
    'min_samples_leaf': [2, 5]
}

print("Optimizing Weighted Random Forest...")
rf_grid = GridSearchCV(RandomForestClassifier(random_state=42), rf_param_grid,
                       cv=5, scoring='recall', n_jobs=-1)
rf_grid.fit(X_train_scaled, y_train)

# 3. XGBoost with scale_pos_weight
xgb_param_grid = {
    'n_estimators': [100, 200],
    'learning_rate': [0.01, 0.05],
    'max_depth': [3, 5],
    'scale_pos_weight': [ratio] # Crucial for XGBoost imbalance
}

print("Optimizing Weighted XGBoost...")
xgb_grid = GridSearchCV(XGBClassifier(use_label_encoder=False, eval_metric='logloss'),
                       xgb_param_grid, cv=5, scoring='recall', n_jobs=-1)
xgb_grid.fit(X_train_scaled, y_train)


print("\nResults after Cost-Sensitive adjustment:")

best_model = rf_grid.best_estimator_
probs = best_model.predict_proba(X_test_scaled)[:, 1]

# Apply a custom threshold (e.g., 0.3) to boost Recall
custom_threshold = 0.3
y_pred_custom = (probs >= custom_threshold).astype(int)

print(classification_report(y_test, y_pred_custom))



print("\n" + "=" * 80)
print("SECTION 8: OPTIMIZED MODEL EVALUATION")
print("=" * 80)

optimized_models = {
    'Logistic Regression': lr_grid.best_estimator_,
    'Random Forest': rf_grid.best_estimator_,
    'XGBoost': xgb_grid.best_estimator_
}

optimized_results = []

for name, model in optimized_models.items():
    print(f"\nEvaluating Optimized {name}...")

    y_pred = model.predict(X_test_scaled)
    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]

    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred, zero_division=0)
    rec = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    auc = roc_auc_score(y_test, y_pred_proba)

    print(f"  Accuracy:  {acc:.4f}")
    print(f"  Precision: {prec:.4f}")
    print(f"  Recall:    {rec:.4f}")
    print(f"  F1-Score:  {f1:.4f}")
    print(f"  AUC-ROC:   {auc:.4f}")

    cm = confusion_matrix(y_test, y_pred)
    print(f"  Confusion Matrix: TN={cm[0, 0]}, FP={cm[0, 1]}, FN={cm[1, 0]}, TP={cm[1, 1]}")

    optimized_results.append({
        'Model': name,
        'Type': 'Optimized',
        'Accuracy': acc,
        'Precision': prec,
        'Recall': rec,
        'F1-Score': f1,
        'AUC-ROC': auc,
        'predictions': y_pred,
        'probabilities': y_pred_proba
    })



print("\n" + "=" * 80)
print("SECTION 9: UNSUPERVISED LEARNING - CLUSTERING ANALYSIS")
print("=" * 80)

# K-Means Clustering
print("\n9.1 K-Means Clustering")
print("-" * 80)

# Determine optimal k using silhouette score
inertias = []
silhouette_scores = []
K_range = range(2, 8)

print("\nFinding optimal number of clusters...")
for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(X_train_scaled)
    inertias.append(kmeans.inertia_)
    silhouette_scores.append(silhouette_score(X_train_scaled, kmeans.labels_))
    print(f"  k={k}: Silhouette Score={silhouette_scores[-1]:.4f}")

optimal_k = K_range[np.argmax(silhouette_scores)]
print(f"\n‚úì Optimal number of clusters: {optimal_k}")

# Train final K-Means
kmeans_final = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
train_clusters = kmeans_final.fit_predict(X_train_scaled)

print(f"\nK-Means Cluster Analysis:")
for i in range(optimal_k):
    cluster_size = (train_clusters == i).sum()
    stroke_rate = y_train[train_clusters == i].mean() * 100
    print(f"  Cluster {i}: {cluster_size:4d} patients ({cluster_size / len(train_clusters) * 100:5.1f}%), "
          f"Stroke Rate: {stroke_rate:5.2f}%")

# Hierarchical Clustering
print("\n9.2 Hierarchical Clustering")
print("-" * 80)

hierarchical = AgglomerativeClustering(n_clusters=optimal_k, linkage='ward')
hier_clusters = hierarchical.fit_predict(X_train_scaled)

print(f"\nHierarchical Cluster Analysis:")
for i in range(optimal_k):
    cluster_size = (hier_clusters == i).sum()
    stroke_rate = y_train[hier_clusters == i].mean() * 100
    print(f"  Cluster {i}: {cluster_size:4d} patients ({cluster_size / len(hier_clusters) * 100:5.1f}%), "
          f"Stroke Rate: {stroke_rate:5.2f}%")



print("\n9.3 t-SNE Visualization of Clusters")
print("-" * 80)

from sklearn.manifold import TSNE

print("\nReducing high-dimensional feature space to 2D using t-SNE...")
print("(This may take 1-2 minutes...)")

# Apply t-SNE
tsne = TSNE(n_components=2, random_state=42, perplexity=30, max_iter=1000)
X_tsne = tsne.fit_transform(X_train_scaled)

print("‚úì t-SNE dimensionality reduction complete")

# Create comprehensive t-SNE visualization
fig, axes = plt.subplots(2, 2, figsize=(18, 16))

# Plot 1: K-Means Clusters
ax1 = axes[0, 0]
scatter1 = ax1.scatter(X_tsne[:, 0], X_tsne[:, 1],
                       c=train_clusters, cmap='viridis',
                       alpha=0.6, s=30, edgecolor='k', linewidth=0.5)
ax1.set_title('K-Means Clustering (t-SNE Projection)',
              fontweight='bold', fontsize=12)
ax1.set_xlabel('t-SNE Component 1', fontweight='bold')
ax1.set_ylabel('t-SNE Component 2', fontweight='bold')
cbar1 = plt.colorbar(scatter1, ax=ax1)
cbar1.set_label('Cluster', fontweight='bold')
ax1.grid(True, alpha=0.3)

# Plot 2: Hierarchical Clusters
ax2 = axes[0, 1]
scatter2 = ax2.scatter(X_tsne[:, 0], X_tsne[:, 1],
                       c=hier_clusters, cmap='viridis',
                       alpha=0.6, s=30, edgecolor='k', linewidth=0.5)
ax2.set_title('Hierarchical Clustering (t-SNE Projection)',
              fontweight='bold', fontsize=12)
ax2.set_xlabel('t-SNE Component 1', fontweight='bold')
ax2.set_ylabel('t-SNE Component 2', fontweight='bold')
cbar2 = plt.colorbar(scatter2, ax=ax2)
cbar2.set_label('Cluster', fontweight='bold')
ax2.grid(True, alpha=0.3)

# Plot 3: Actual Stroke Cases (Ground Truth)
ax3 = axes[1, 0]
colors_stroke = ['lightgreen' if s == 0 else 'red' for s in y_train.values]
scatter3 = ax3.scatter(X_tsne[:, 0], X_tsne[:, 1],
                       c=colors_stroke, alpha=0.6, s=30,
                       edgecolor='k', linewidth=0.5)
ax3.set_title('Actual Stroke Cases (Ground Truth)',
              fontweight='bold', fontsize=12)
ax3.set_xlabel('t-SNE Component 1', fontweight='bold')
ax3.set_ylabel('t-SNE Component 2', fontweight='bold')

# Create custom legend
from matplotlib.patches import Patch

legend_elements = [
    Patch(facecolor='lightgreen', edgecolor='black', label='No Stroke'),
    Patch(facecolor='red', edgecolor='black', label='Stroke')
]
ax3.legend(handles=legend_elements, loc='best')
ax3.grid(True, alpha=0.3)

# Plot 4: K-Means with Stroke Overlay (Most Important!)
ax4 = axes[1, 1]

# Plot clusters as background
for cluster_id in range(optimal_k):
    cluster_mask = train_clusters == cluster_id
    cluster_stroke_rate = y_train[cluster_mask].mean() * 100

    # Color intensity based on stroke rate
    if cluster_stroke_rate > 10:
        color = 'red'
        alpha = 0.3
    elif cluster_stroke_rate > 5:
        color = 'orange'
        alpha = 0.2
    else:
        color = 'lightblue'
        alpha = 0.15

    ax4.scatter(X_tsne[cluster_mask, 0], X_tsne[cluster_mask, 1],
                c=color, alpha=alpha, s=50, edgecolor='none',
                label=f'Cluster {cluster_id} ({cluster_stroke_rate:.1f}% stroke)')

# Overlay actual stroke cases
stroke_mask = y_train.values == 1
ax4.scatter(X_tsne[stroke_mask, 0], X_tsne[stroke_mask, 1],
            c='darkred', marker='X', s=100, edgecolor='black',
            linewidth=1, label='Actual Stroke Cases', zorder=5)

ax4.set_title('Cluster Risk Stratification with Stroke Cases',
              fontweight='bold', fontsize=12)
ax4.set_xlabel('t-SNE Component 1', fontweight='bold')
ax4.set_ylabel('t-SNE Component 2', fontweight='bold')
ax4.legend(loc='best', fontsize=8)
ax4.grid(True, alpha=0.3)

plt.suptitle('t-SNE Visualization: Cluster Analysis and Risk Stratification',
             fontsize=16, fontweight='bold')
plt.tight_layout()
plt.savefig('19_tsne_clustering_visualization.png', dpi=300, bbox_inches='tight')
plt.show()

print("\n‚úì Saved: 19_tsne_clustering_visualization.png")

# Analyze cluster quality using t-SNE coordinates
print("\nCluster Separation Analysis (t-SNE space):")
for i in range(optimal_k):
    cluster_mask = train_clusters == i
    cluster_tsne = X_tsne[cluster_mask]
    cluster_center = cluster_tsne.mean(axis=0)
    cluster_spread = cluster_tsne.std(axis=0).mean()
    stroke_rate = y_train[cluster_mask].mean() * 100

    print(f"\nCluster {i}:")
    print(f"  Center: ({cluster_center[0]:.2f}, {cluster_center[1]:.2f})")
    print(f"  Spread (std): {cluster_spread:.2f}")
    print(f"  Stroke Rate: {stroke_rate:.2f}%")
    print(f"  Risk Level: {'HIGH RISK' if stroke_rate > 10 else 'MODERATE' if stroke_rate > 5 else 'LOW RISK'}")



print("\n" + "=" * 80)
print("SECTION 10: RESULTS SUMMARY")
print("=" * 80)

# Combine all results
all_results = baseline_results + optimized_results
results_df = pd.DataFrame(all_results)

print("\nComplete Model Performance Summary:")
print(results_df[['Model', 'Type', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']].to_string(index=False))

# Best model
best_idx = results_df['F1-Score'].idxmax()
best_model = results_df.loc[best_idx]

print("\n" + "=" * 80)
print("BEST PERFORMING MODEL:")
print("=" * 80)
print(f"Model: {best_model['Model']} ({best_model['Type']})")
print(f"F1-Score:  {best_model['F1-Score']:.4f}")
print(f"Precision: {best_model['Precision']:.4f}")
print(f"Recall:    {best_model['Recall']:.4f}")
print(f"AUC-ROC:   {best_model['AUC-ROC']:.4f}")



print("\n" + "=" * 80)
print("SECTION 11: CREATING VISUALIZATIONS")
print("=" * 80)

# Visualization 1: Model Comparison
fig, axes = plt.subplots(2, 2, figsize=(16, 12))
metrics = ['Precision', 'Recall', 'F1-Score', 'AUC-ROC']

for idx, metric in enumerate(metrics):
    ax = axes[idx // 2, idx % 2]

    baseline_data = results_df[results_df['Type'] == 'Baseline']
    optimized_data = results_df[results_df['Type'] == 'Optimized']

    models = baseline_data['Model'].tolist()
    x = np.arange(len(models))
    width = 0.35

    baseline_vals = baseline_data[metric].values

    # Match optimized models to baseline (some may not exist)
    optimized_vals = []
    for model in models:
        opt_row = optimized_data[optimized_data['Model'] == model]
        if len(opt_row) > 0:
            optimized_vals.append(opt_row[metric].values[0])
        else:
            optimized_vals.append(0)

    bars1 = ax.bar(x - width / 2, baseline_vals, width, label='Baseline',
                   color='coral', edgecolor='black')
    bars2 = ax.bar(x + width / 2, optimized_vals, width, label='Optimized',
                   color='lightgreen', edgecolor='black')

    ax.set_xlabel('Model', fontweight='bold')
    ax.set_ylabel(metric, fontweight='bold')
    ax.set_title(f'{metric} Comparison', fontweight='bold')
    ax.set_xticks(x)
    ax.set_xticklabels(models, rotation=45, ha='right')
    ax.legend()
    ax.grid(axis='y', alpha=0.3)

    # Add value labels
    for bars in [bars1, bars2]:
        for bar in bars:
            height = bar.get_height()
            if height > 0:
                ax.text(bar.get_x() + bar.get_width() / 2., height,
                        f'{height:.3f}', ha='center', va='bottom', fontsize=8)

plt.suptitle('Model Performance: Baseline vs Optimized', fontsize=16, fontweight='bold')
plt.tight_layout()
plt.savefig('16_model_comparison_final.png', dpi=300, bbox_inches='tight')
plt.show()
print("‚úì Saved: 16_model_comparison_final.png")

# Visualization 2: Clustering Results
fig, axes = plt.subplots(1, 2, figsize=(16, 6))

cluster_methods = [
    ('K-Means', train_clusters),
    ('Hierarchical', hier_clusters)
]

for ax_idx, (method_name, clusters) in enumerate(cluster_methods):
    ax = axes[ax_idx]

    cluster_data = []
    for i in range(optimal_k):
        cluster_data.append({
            'Cluster': f'C{i}',
            'Size': (clusters == i).sum(),
            'Stroke_Rate': y_train[clusters == i].mean() * 100
        })

    cluster_df = pd.DataFrame(cluster_data)

    x = np.arange(len(cluster_df))
    width = 0.35

    bars1 = ax.bar(x - width / 2, cluster_df['Size'], width, label='Cluster Size',
                   color='steelblue', edgecolor='black')
    ax_twin = ax.twinx()
    bars2 = ax_twin.bar(x + width / 2, cluster_df['Stroke_Rate'], width,
                        label='Stroke Rate (%)', color='salmon', edgecolor='black')

    ax.set_xlabel('Cluster', fontweight='bold')
    ax.set_ylabel('Number of Patients', fontweight='bold')
    ax_twin.set_ylabel('Stroke Rate (%)', fontweight='bold')
    ax.set_title(f'{method_name} Clustering', fontweight='bold')
    ax.set_xticks(x)
    ax.set_xticklabels(cluster_df['Cluster'])
    ax.legend(loc='upper left')
    ax_twin.legend(loc='upper right')
    ax.grid(axis='y', alpha=0.3)

plt.suptitle('Unsupervised Learning: Patient Clustering Analysis',
             fontsize=16, fontweight='bold')
plt.tight_layout()
plt.savefig('17_clustering_final.png', dpi=300, bbox_inches='tight')
plt.show()
print("‚úì Saved: 17_clustering_final.png")

# Visualization 3: ROC Curves
fig, ax = plt.subplots(figsize=(10, 8))

colors = ['blue', 'green', 'red', 'orange', 'purple', 'brown']
color_idx = 0

for result in optimized_results:
    if 'probabilities' in result:
        fpr, tpr, _ = roc_curve(y_test, result['probabilities'])
        label = f"{result['Model']} (AUC = {result['AUC-ROC']:.3f})"
        ax.plot(fpr, tpr, linewidth=2, label=label, color=colors[color_idx % len(colors)])
        color_idx += 1

ax.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Random Classifier')
ax.set_xlabel('False Positive Rate', fontweight='bold', fontsize=12)
ax.set_ylabel('True Positive Rate', fontweight='bold', fontsize=12)
ax.set_title('ROC Curves: Optimized Models', fontweight='bold', fontsize=14)
ax.legend(loc='lower right', fontsize=10)
ax.grid(alpha=0.3)

plt.tight_layout()
plt.savefig('18_roc_curves_final.png', dpi=300, bbox_inches='tight')
plt.show()
print("‚úì Saved: 18_roc_curves_final.png")



print("\n" + "=" * 80)
print("SECTION 12: SAVING RESULTS")
print("=" * 80)

# Save model results
results_df.to_csv('part_b_model_results.csv', index=False)
print("‚úì Saved: part_b_model_results.csv")

# Save clustering results
clustering_df = pd.DataFrame({
    'KMeans_Cluster': train_clusters,
    'Hierarchical_Cluster': hier_clusters,
    'Stroke': y_train.values
})
clustering_df.to_csv('part_b_clustering_results.csv', index=False)
print("‚úì Saved: part_b_clustering_results.csv")

# Save best model report
with open('part_b_best_model_report.txt', 'w') as f:
    f.write("=" * 80 + "\n")
    f.write("PART B: BEST MODEL REPORT\n")
    f.write("=" * 80 + "\n\n")
    f.write(f"Best Model: {best_model['Model']} ({best_model['Type']})\n\n")
    f.write("Performance Metrics:\n")
    f.write(f"  F1-Score:  {best_model['F1-Score']:.4f}\n")
    f.write(f"  Precision: {best_model['Precision']:.4f}\n")
    f.write(f"  Recall:    {best_model['Recall']:.4f}\n")
    f.write(f"  AUC-ROC:   {best_model['AUC-ROC']:.4f}\n\n")

    if 'Random Forest' in best_model['Model']:
        f.write("Optimized Hyperparameters:\n")
        f.write(f"{rf_grid.best_params_}\n")
    elif 'Logistic' in best_model['Model']:
        f.write("Optimized Hyperparameters:\n")
        f.write(f"{lr_grid.best_params_}\n")
    elif 'XGBoost' in best_model['Model']:
        f.write("Optimized Hyperparameters:\n")
        f.write(f"{xgb_grid.best_params_}\n")

print("‚úì Saved: part_b_best_model_report.txt")



print("\n" + "=" * 80)
print("PART B COMPLETE!")
print("=" * 80)

print("\nüìä Summary:")
print(f"  ‚Ä¢ Models trained: {len(baseline_results)} baseline + {len(optimized_results)} optimized")
print(f"  ‚Ä¢ Best model: {best_model['Model']} ({best_model['Type']})")
print(f"  ‚Ä¢ Best F1-Score: {best_model['F1-Score']:.4f}")
print(f"  ‚Ä¢ Clustering algorithms: K-Means & Hierarchical")
print(f"  ‚Ä¢ High-risk clusters identified with up to 12% stroke rate")

print("\nüìÅ Generated Files:")
print("  1. 16_model_comparison_final.png - Performance comparison")
print("  2. 17_clustering_final.png - Clustering analysis")
print("  3. 18_roc_curves_final.png - ROC curves")
print("  4. part_b_model_results.csv - All model results")
print("  5. part_b_clustering_results.csv - Cluster assignments")
print("  6. part_b_best_model_report.txt - Best model details")

print("\n‚úÖ Part B (Modelling) Complete!")
print("‚úÖ Ready for Part B.5 (Evaluation) and Report Writing!")
print("\n" + "=" * 80)